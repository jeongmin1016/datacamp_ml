{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31eb4d03",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef613382",
   "metadata": {},
   "source": [
    "분류 문제와 어떻게 풀이를 하는지 학습할 계획   \n",
    "how to split data into training and test sets, fit a model, make predictions, and evaluate accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852160d5",
   "metadata": {},
   "source": [
    "### The supervised learning workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2d80926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.2'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e265265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.module import Model # 에러 발생 - 업데이트 문제인가\n",
    "model = Model()\n",
    "model.fit(X,y)\n",
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55db7958",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors:Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "# Create arrays for the features and the target variable\n",
    "y = churn_df[\"churn\"].values\n",
    "X = churn_df[[\"account_length\", \"customer_service_calls\"]].values\n",
    "\n",
    "# Create a KNN classifier with 6 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2d1b6f",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors:Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the X_new\n",
    "y_pred = knn.predict(X_new)\n",
    "\n",
    "# Print the predictions for X_new\n",
    "print(\"Predictions: {}\".format(y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab72ae",
   "metadata": {},
   "source": [
    "### Train/test split + computing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f42a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = churn_df.drop(\"churn\", axis=1).values\n",
    "y = churn_df[\"churn\"].values\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f8a60a",
   "metadata": {},
   "source": [
    "stratify 파라미터에 Outcome 컬럼을 넣어주는 경우  \n",
    "정오행렬표를 이용해 다시 확인해 보면 비율이 유지되어 있는 것이 확인된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c51346",
   "metadata": {},
   "source": [
    "### overfitting and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753be495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neighbors\n",
    "neighbors = np.arange(1,13)\n",
    "train_accuracies = {}\n",
    "test_accuracies = {}\n",
    "\n",
    "for neighbor in neighbors:\n",
    "  \n",
    "    # Set up a KNN Classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbor)\n",
    "  \n",
    "    # Fit the model\n",
    "    knn.fit(X_train, y_train)\n",
    "  \n",
    "    # Compute accuracy\n",
    "    train_accuracies[neighbor] = knn.score(X_train, y_train)\n",
    "    test_accuracies[neighbor] = knn.score(X_test, y_test)\n",
    "    \n",
    "print(neighbors, '\\n', train_accuracies, '\\n', test_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f358d",
   "metadata": {},
   "source": [
    "### Visualizing model complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2da9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a title\n",
    "plt.title(\"KNN: Varying Number of Neighbors\")\n",
    "\n",
    "# Plot training accuracies\n",
    "plt.plot(neighbors, train_accuracies.values(), label=\"Training Accuracy\")\n",
    "\n",
    "# Plot test accuracies\n",
    "plt.plot(neighbors, test_accuracies.values(), label=\"Testing Accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a8e9d0",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a748eb",
   "metadata": {},
   "source": [
    "### creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0b382ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create X from the radio column's values\n",
    "X = sales_df[\"radio\"].values\n",
    "\n",
    "# Create y from the sales column's values\n",
    "y = sales_df[\"sales\"].values\n",
    "\n",
    "# Reshape X\n",
    "X = X.reshape(-1, 1) # 스케일링의 역할\n",
    "\n",
    "# Check the shape of the features and targets\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa726734",
   "metadata": {},
   "source": [
    "### Building a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create the model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "reg.fit(X,y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = reg.predict(X)\n",
    "\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a578ef",
   "metadata": {},
   "source": [
    "### Visualizing a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c93095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(X, y, color=\"blue\")\n",
    "\n",
    "# Create line plot\n",
    "plt.plot(X, predictions, color=\"red\") # the predictions on the y-axis\n",
    "plt.xlabel(\"Radio Expenditure ($)\")\n",
    "plt.ylabel(\"Sales ($)\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84e6d72",
   "metadata": {},
   "source": [
    "### Fit and predict for regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba9a10c",
   "metadata": {},
   "source": [
    "###### y = ax + b \n",
    "y : target   \n",
    "x : single feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad973c42",
   "metadata": {},
   "source": [
    "###### RSS :  the residual sum of squares\n",
    "-> 최소로 하는 것이 우리의 목표 \n",
    "\n",
    "###### R-squared : quantifies the variance in target values\n",
    "values range from 0 to 1   \n",
    "값이 작을 수록 멀리 퍼져있고 클수록 선형의 형태를 보임\n",
    "\n",
    "###### MSE : Mean squared error\n",
    "MSE 각 y값에서 추정값과의 편차 제곱의 평균   \n",
    "MSE에 제곱근이 RMSE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe1a1b",
   "metadata": {},
   "source": [
    "### Regression performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c352991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y arrays\n",
    "X = sales_df.drop(\"sales\", axis=1).values\n",
    "y = sales_df[\"sales\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate the model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "reg.fit(X_train,y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"Predictions: {}, Actual Values: {}\".format(y_pred[:2], y_test[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5620794f",
   "metadata": {},
   "source": [
    "### Cross-validation for R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5813c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Compute R-squared\n",
    "r_squared = reg.score(X_test, y_test)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"R^2: {}\".format(r_squared))\n",
    "print(\"RMSE: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1524bd",
   "metadata": {},
   "source": [
    "### Analyzing cross-validation metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81264b72",
   "metadata": {},
   "source": [
    "##### cross_val_score 교차검증  \n",
    "일반화 성능을 평가하는데에 데이터 분할로 한번 나누는 것보다 더 안정적임     \n",
    "교차검증에서는 데이터를 여러번 반복해 나누고 여러모델 학습 \n",
    "\n",
    "##### KFold - scikit learn의 교차검증\n",
    "데이터가 랜덤하지 않은 경우 적용에 주의해야 함    \n",
    "검증을 하기 위해 데이터를 분리할 때 train test 로 분리하지 않고 train 을 train과 valid 로 분할하여 검증한다. 이때 데이터의 수가 작은 경우 제대로 할 수 없음 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a760806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=5)\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Compute 6-fold cross-validation scores\n",
    "cv_scores = cross_val_score(reg, X, y, cv=kf)\n",
    "\n",
    "# Print scores\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0be24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean\n",
    "print(np.mean(cv_results))\n",
    "\n",
    "# Print the standard deviation\n",
    "print(np.std(cv_results))\n",
    "\n",
    "# Print the 95% confidence interval\n",
    "print(np.quantile(cv_results, [0.025, 0.975]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef7e97e",
   "metadata": {},
   "source": [
    "### Regularized regression:Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a6a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "alphas = [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
    "ridge_scores = []\n",
    "for alpha in alphas:\n",
    "  \n",
    "  # Create a Ridge regression model\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "  \n",
    "  # Fit the data\n",
    "    ridge.fit(X_train, y_train)\n",
    "  \n",
    "  # Obtain R-squared\n",
    "    score = ridge.score(X_test,y_test)\n",
    "    ridge_scores.append(score)\n",
    "print(ridge_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c0d7a2",
   "metadata": {},
   "source": [
    "### Lasso regression for feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Instantiate a lasso regression model\n",
    "lasso = Lasso(alpha=0.3)\n",
    "\n",
    "# Fit the model to the data\n",
    "lasso.fit(X,y)\n",
    "\n",
    "# Compute and print the coefficients\n",
    "lasso_coef = lasso.fit(X,y).coef_\n",
    "print(lasso_coef)\n",
    "plt.bar(sales_columns, lasso_coef)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d326f6",
   "metadata": {},
   "source": [
    "# Fine-Tuning Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7339071e",
   "metadata": {},
   "source": [
    "정확도 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49306d85",
   "metadata": {},
   "source": [
    "### Assessing a diabetes prediction classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2902819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f84e81a9",
   "metadata": {},
   "source": [
    "### Building a logistic regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c756d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(y_pred_probs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a877f17",
   "metadata": {},
   "source": [
    "### The ROC curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import roc_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# Plot tpr against fpr\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Diabetes Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f27dd1",
   "metadata": {},
   "source": [
    "### ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb9538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate roc_auc_score\n",
    "print(roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fed7263",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with GridsearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88853ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\"alpha\": np.linspace(0.00001, 1, 20)}\n",
    "\n",
    "# Instantiate lasso_cv\n",
    "lasso_cv = GridSearchCV(lasso, param_grid, cv=kf)\n",
    "\n",
    "# Fit to the training data\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "print(\"Tuned lasso paramaters: {}\".format(lasso_cv.best_params_))\n",
    "print(\"Tuned lasso score: {}\".format(lasso_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413822d8",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter space\n",
    "params = {\"penalty\": [\"l1\", \"l2\"],\n",
    "         \"tol\": np.linspace(0.0001, 1.0, 50),\n",
    "         \"C\": np.linspace(0.1, 1.0, 50),\n",
    "         \"class_weight\": [\"balanced\", {0:0.8, 1:0.2}]}\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "logreg_cv = RandomizedSearchCV(logreg, params, cv=kf)\n",
    "\n",
    "# Fit the data to the model\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Best Accuracy Score: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba334f2",
   "metadata": {},
   "source": [
    "# Preprocessing and Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99863bb2",
   "metadata": {},
   "source": [
    "### Creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f767678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create music_dummies\n",
    "music_dummies = pd.get_dummies(music_df, drop_first=True)\n",
    "\n",
    "# Print the new DataFrame's shape\n",
    "print(\"Shape of music_dummies: {}\".format(music_dummies.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db21363e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
